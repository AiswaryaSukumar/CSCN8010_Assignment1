{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Lab 1: Streaming Data for Predictive Maintenance with Linear Regression-Based Alerts\n",
    "\n",
    "## Overview\n",
    "This notebook implements a predictive maintenance system for industrial current data (axes 1-8). It:\n",
    "- Connects to a Neon.tech PostgreSQL database to pull training data.\n",
    "- Fits linear regression models (Time ‚Üí Axis values) for axes 1-8.\n",
    "- Analyzes residuals to discover alert/error thresholds (MinC, MaxC, T).\n",
    "- Generates synthetic test data to simulate streaming.\n",
    "- Detects alerts/errors based on thresholds and logs events.\n",
    "- Visualizes regression fits, residuals, and annotated alerts/errors.\n",
    "\n",
    "The goal is to detect anomalies in current data to flag potential failures early, using evidence-based thresholds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Environment and Connect to Database\n",
    "Pull training data from Neon.tech PostgreSQL, convert time to numeric, and export to CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Load .env file\n",
    "load_dotenv()\n",
    "\n",
    "PGHOST = os.getenv('PGHOST')\n",
    "PGPORT = os.getenv('PGPORT', '5432')\n",
    "PGDATABASE = os.getenv('PGDATABASE')\n",
    "PGUSER = os.getenv('PGUSER')\n",
    "PGPASSWORD = os.getenv('PGPASSWORD')\n",
    "PGSSL = os.getenv('PGSSL', 'require')\n",
    "\n",
    "assert PGHOST and PGDATABASE and PGUSER and PGPASSWORD, '‚ùå Missing DB env vars. Check your .env file!'\n",
    "\n",
    "# Build SQLAlchemy engine\n",
    "engine = create_engine(\n",
    "    f'postgresql+psycopg2://{PGUSER}:{PGPASSWORD}@{PGHOST}:{PGPORT}/{PGDATABASE}?sslmode={PGSSL}',\n",
    "    pool_pre_ping=True\n",
    ")\n",
    "\n",
    "# Query staging_measurements\n",
    "query = '''\n",
    "SELECT time, axis1, axis2, axis3, axis4, axis5, axis6, axis7, axis8\n",
    "FROM staging_measurements\n",
    "'''\n",
    "\n",
    "# Load into DataFrame\n",
    "df_train = pd.read_sql(query, engine)\n",
    "\n",
    "# Ensure datetime and sort\n",
    "df_train['time'] = pd.to_datetime(df_train['time'])\n",
    "df_train.sort_values('time', inplace=True)\n",
    "\n",
    "# Convert time to numeric (seconds since start)\n",
    "df_train['time_numeric'] = (df_train['time'] - df_train['time'].min()).dt.total_seconds()\n",
    "\n",
    "# Save to CSV\n",
    "os.makedirs('Data', exist_ok=True)\n",
    "df_train.to_csv('Data/Training_data.csv', index=False)\n",
    "\n",
    "print('‚úÖ Data exported from staging_measurements to Data/Training_data.csv')\n",
    "print(df_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Linear Regression Models and Analyze Residuals\n",
    "Fit univariate regression models (Time ‚Üí Axes 1-8), compute slopes/intercepts, and analyze residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "pd.set_option('display.width', 120)\n",
    "pd.set_option('display.max_columns', 20)\n",
    "\n",
    "DATA_DIR = Path('Data')\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "AXES = ['axis1', 'axis2', 'axis3', 'axis4', 'axis5', 'axis6', 'axis7', 'axis8']\n",
    "\n",
    "# Load training data\n",
    "train_path = DATA_DIR / 'Training_data.csv'\n",
    "assert train_path.exists(), '‚ùå Training_data.csv not found. Run DB cell first.'\n",
    "df_train = pd.read_csv(train_path)\n",
    "df_train['time'] = pd.to_datetime(df_train['time'])\n",
    "df_train = df_train.sort_values('time').reset_index(drop=True)\n",
    "\n",
    "# Ensure time_numeric\n",
    "if 'time_numeric' not in df_train.columns:\n",
    "    df_train['time_numeric'] = (df_train['time'] - df_train['time'].min()).dt.total_seconds()\n",
    "\n",
    "# Drop missing values\n",
    "df_train = df_train.dropna(subset=['time_numeric'] + AXES)\n",
    "\n",
    "# Estimate sampling interval\n",
    "time_diffs = df_train['time'].diff().dt.total_seconds()\n",
    "sample_interval_sec = float(np.nanmedian(time_diffs))\n",
    "print(f'Estimated sampling interval: {sample_interval_sec:.3f} seconds')\n",
    "\n",
    "# Fit models\n",
    "models = {}\n",
    "slopes = {}\n",
    "intercepts = {}\n",
    "residuals_dict = {}\n",
    "X = df_train[['time_numeric']].values\n",
    "\n",
    "for axis in AXES:\n",
    "    y = df_train[axis].values\n",
    "    mdl = LinearRegression()\n",
    "    mdl.fit(X, y)\n",
    "    models[axis] = mdl\n",
    "    slopes[axis] = float(mdl.coef_[0])\n",
    "    intercepts[axis] = float(mdl.intercept_)\n",
    "    y_pred = mdl.predict(X)\n",
    "    residuals_dict[axis] = y - y_pred\n",
    "\n",
    "# Summaries\n",
    "model_summary = pd.DataFrame({\n",
    "    'axis': AXES,\n",
    "    'slope': [slopes[a] for a in AXES],\n",
    "    'intercept': [intercepts[a] for a in AXES]\n",
    "}).sort_values('axis')\n",
    "\n",
    "residual_stats = pd.DataFrame({\n",
    "    'axis': AXES,\n",
    "    'residual_mean': [float(np.mean(residuals_dict[a])) for a in AXES],\n",
    "    'residual_std': [float(np.std(residuals_dict[a], ddof=0)) for a in AXES],\n",
    "}).sort_values('axis')\n",
    "\n",
    "# Save artifacts\n",
    "model_summary.to_csv(DATA_DIR / 'model_params.csv', index=False)\n",
    "residual_stats.to_csv(DATA_DIR / 'residual_stats.csv', index=False)\n",
    "\n",
    "print('\\nüìä Model parameters (slopes/intercepts):')\n",
    "print(model_summary)\n",
    "print('\\nüìä Residual stats (mean/std):')\n",
    "print(residual_stats)\n",
    "print('\\n‚úÖ Ready: models, residuals_dict, model_params.csv, residual_stats.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Regression Fits and Residuals\n",
    "Plot training data with regression lines and residual distributions to identify patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n",
    "\n",
    "# Plot regression lines\n",
    "fig, axs = plt.subplots(4, 2, figsize=(15, 20), sharex=True)\n",
    "axs = axs.flatten()\n",
    "for i, axis in enumerate(AXES):\n",
    "    axs[i].scatter(df_train['time_numeric'], df_train[axis], s=5, alpha=0.5, label='Data')\n",
    "    y_pred = models[axis].predict(X)\n",
    "    axs[i].plot(df_train['time_numeric'], y_pred, color='red', label='Regression Line')\n",
    "    axs[i].set_title(f'{axis}: Data vs Time')\n",
    "    axs[i].set_ylabel(axis)\n",
    "    axs[i].legend()\n",
    "    axs[i].grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot residual distributions\n",
    "fig, axs = plt.subplots(4, 2, figsize=(15, 20))\n",
    "axs = axs.flatten()\n",
    "for i, axis in enumerate(AXES):\n",
    "    axs[i].hist(residuals_dict[axis], bins=50, color='blue', alpha=0.7)\n",
    "    axs[i].set_title(f'{axis}: Residual Histogram')\n",
    "    axs[i].set_xlabel('Residual')\n",
    "    axs[i].grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threshold Discovery and Justification\n",
    "Analyze residuals to define MinC, MaxC, and T for alerts/errors.\n",
    "\n",
    "**Observations**:\n",
    "- Residuals are normally distributed around mean ~0 (from stats).\n",
    "- Std devs vary (0.4 for axis8, up to 6.9 for axis2), indicating different scales.\n",
    "- Normalization check: Axes have different ranges (e.g., axis2 mean~3.5, axis8 mean~0.1). Z-scores standardize residuals for comparison (std~1 post-scaling).\n",
    "- Predictive maintenance context: Alerts catch early trends (e.g., wear); errors flag critical failures.\n",
    "\n",
    "**Thresholds**:\n",
    "- **MinC** = 2 * std per axis (~95th percentile, catches outliers for alerts).\n",
    "- **MaxC** = 4 * std per axis (~99.99th percentile, rare extremes for errors).\n",
    "- **T** = 20 sec (matches min anomaly block, ensures sustained issues).\n",
    "\n",
    "**Justification**:\n",
    "- Residual histograms show Gaussian-like distributions; 2*std captures most outliers, 4*std rare extremes.\n",
    "- T=20 sec aligns with synthetic data anomaly blocks (20-25 sec), avoiding noise.\n",
    "- Per-axis thresholds account for scale differences, ensuring sensitivity (e.g., axis8 small std needs tighter thresholds).\n",
    "- Predictive maintenance: Early alerts (MinC) flag trends for inspection; errors (MaxC) indicate urgent issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define thresholds\n",
    "MinC = {axis: 2 * residual_stats.loc[residual_stats['axis'] == axis, 'residual_std'].values[0] for axis in AXES}\n",
    "MaxC = {axis: 4 * residual_stats.loc[residual_stats['axis'] == axis, 'residual_std'].values[0] for axis in AXES}\n",
    "T = 20  # seconds\n",
    "\n",
    "print('MinC (Alert thresholds):', MinC)\n",
    "print('MaxC (Error thresholds):', MaxC)\n",
    "print('T (min duration sec):', T)\n",
    "\n",
    "# Normalization check: Compute Z-scores for residuals\n",
    "res_std = {axis: residual_stats.loc[residual_stats['axis'] == axis, 'residual_std'].values[0] for axis in AXES}\n",
    "z_scores = {axis: residuals_dict[axis] / res_std[axis] for axis in AXES}\n",
    "print('Z-scores std (should be ~1):', {axis: np.std(z_scores[axis]) for axis in AXES})  # Validates standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Synthetic Test Data (Streaming Simulation)\n",
    "Use `synthetic_data.py` to generate test data mimicking a stream. Process in chunks to simulate streaming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from synthetic_data import make_synthetic_test\n",
    "\n",
    "# Generate test data\n",
    "df_test, sample_interval_sec = make_synthetic_test(\n",
    "    df_train, models, AXES, n_rows=5000, sample_interval_sec=sample_interval_sec,\n",
    "    residuals_dict=residuals_dict, force_above=True, MinC=MinC, MaxC=MaxC\n",
    ")\n",
    "df_test.to_csv('Data/Test_data.csv', index=False)\n",
    "print('‚úÖ Synthetic test data saved to Data/Test_data.csv')\n",
    "print(df_test.head())\n",
    "\n",
    "# Simulate streaming: Process in chunks (100 rows)\n",
    "chunk_size = 100\n",
    "residuals_test = {}\n",
    "X_test = df_test[['time_numeric']].values\n",
    "for axis in AXES:\n",
    "    residuals_test[axis] = []\n",
    "    for i in range(0, len(df_test), chunk_size):\n",
    "        chunk = X_test[i:i+chunk_size]\n",
    "        y_pred = models[axis].predict(chunk)\n",
    "        y_actual = df_test[axis].values[i:i+chunk_size]\n",
    "        residuals_test[axis].extend(y_actual - y_pred)\n",
    "    residuals_test[axis] = np.array(residuals_test[axis])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Alerts and Errors\n",
    "Detect consecutive residuals ‚â• MinC/MaxC for ‚â• T seconds. Log events to CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Event:\n",
    "    axis: str\n",
    "    start_idx: int\n",
    "    end_idx: int\n",
    "    duration_sec: float\n",
    "    peak_residual: float\n",
    "    level: str  # 'ALERT' or 'ERROR'\n",
    "\n",
    "events = []\n",
    "\n",
    "for axis in AXES:\n",
    "    res = residuals_test[axis]\n",
    "    in_event = False\n",
    "    start = None\n",
    "    for i in range(len(res)):\n",
    "        thresh = MaxC[axis] if res[i] >= MaxC[axis] else MinC[axis] if res[i] >= MinC[axis] else 0\n",
    "        if thresh > 0:\n",
    "            if not in_event:\n",
    "                in_event = True\n",
    "                start = i\n",
    "            continue\n",
    "        if in_event:\n",
    "            duration_sec = (i - start) * sample_interval_sec\n",
    "            if duration_sec >= T:\n",
    "                peak = max(res[start:i])\n",
    "                level = 'ERROR' if peak >= MaxC[axis] else 'ALERT'\n",
    "                events.append(Event(axis, start, i-1, duration_sec, peak, level))\n",
    "            in_event = False\n",
    "\n",
    "# Log to CSV\n",
    "events_df = pd.DataFrame([vars(e) for e in events])\n",
    "events_df.to_csv('Data/alerts_errors.csv', index=False)\n",
    "print('‚úÖ Events logged to Data/alerts_errors.csv')\n",
    "print(events_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Residuals with Alerts/Errors\n",
    "Plot residuals with MinC/MaxC thresholds and annotate alerts/errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_residuals_with_events(axis, df, residuals_test, MinC, MaxC, events):\n",
    "    r = residuals_test[axis]\n",
    "    t = df['time'].values\n",
    "\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.plot(t, r, color='blue', linewidth=1, label='Residual')\n",
    "    plt.axhline(MinC[axis], linestyle='--', color='orange', label='MinC')\n",
    "    plt.axhline(MaxC[axis], linestyle='--', color='red', label='MaxC')\n",
    "\n",
    "    for ev in events:\n",
    "        if ev.axis != axis:\n",
    "            continue\n",
    "        plt.axvline(df.loc[ev.start_idx, 'time'], color='green' if ev.level=='ALERT' else 'red',\n",
    "                    linestyle='--', alpha=0.7)\n",
    "        plt.axvline(df.loc[ev.end_idx, 'time'], color='green' if ev.level=='ALERT' else 'red',\n",
    "                    linestyle='--', alpha=0.7)\n",
    "        plt.scatter(df.loc[ev.end_idx, 'time'], ev.peak_residual,\n",
    "                    color='red' if ev.level=='ERROR' else 'orange', marker='x', s=80)\n",
    "        mid_idx = ev.start_idx + (ev.end_idx - ev.start_idx)//2\n",
    "        mid_time = df.loc[mid_idx, 'time']\n",
    "        plt.text(mid_time, ev.peak_residual + 1,\n",
    "                 f'{ev.level}\\n{ev.duration_sec:.1f}s',\n",
    "                 color='red' if ev.level=='ERROR' else 'orange',\n",
    "                 ha='center', va='bottom', fontsize=8,\n",
    "                 bbox=dict(facecolor='white', alpha=0.6, edgecolor='none'))\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.xaxis.set_major_locator(mdates.HourLocator(interval=2))\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.title(f'{axis}: Residuals with Alerts/Errors')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Residual (actual - predicted)')\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'Data/{axis}_residuals_plot.png')  # Save for README\n",
    "    plt.show()\n",
    "\n",
    "# Run for all axes\n",
    "for axis in AXES:\n",
    "    plot_residuals_with_events(axis, df_test, residuals_test, MinC, MaxC, events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "This notebook implements a predictive maintenance pipeline:\n",
    "- Connected to Neon.tech DB, pulled training data.\n",
    "- Fitted linear regression models for axes 1-8.\n",
    "- Analyzed residuals to set MinC (2*std), MaxC (4*std), T (20 sec).\n",
    "- Generated synthetic test data with anomalies.\n",
    "- Simulated streaming by processing in chunks.\n",
    "- Detected/logged alerts/errors based on thresholds.\n",
    "- Visualized fits, residuals, and annotated events.\n",
    "\n",
    "See `Data/` for CSVs and plots. Results align with predictive maintenance: alerts catch early trends, errors flag critical issues."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.9.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}